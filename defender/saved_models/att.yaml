args: !!python/object:argparse.Namespace
  arch: attention
  att_dropout: 0.2
  batch_size: 32
  debug: false
  dropout_rate: 0.2
  early_stopping_patience: 40
  epochs: 8
  evaluate_every: 0.25
  gammas:
  - 0.9
  - 0.9
  hidden_dim:
  - 512
  lbda: 0.5
  learning_rate: 1.0e-05
  loss_type: pauc
  momentum: 0.9
  n_layers: 8
  num_heads: 16
  optimizer: adamw
  pretrained: saved_models/attention/pauc/[0, 1, 2, 3]/version_0/last.ckpt
  resume: null
  save: defender/att.pkl
  save_dir: ./saved_models
  save_every_epochs: 1
  seed: null
  skip_training: null
  tau: 10.0
  warmup_epochs: 0.5
  weight_decay: 0.0002
  workers: 6
features_dim:
- 22
- 77
- 10870
- 2775
num_epochs: 7166
pos_samples: 103979
textual_idx:
- 2
- 3
- 4
- 5
- 6
- 7
use_features:
- 0
- 1
- 2
- 3
val_datasets: 14
