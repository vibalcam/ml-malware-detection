from typing import Callable, List
import pandas as pd
import warnings
from tqdm.auto import tqdm 
import numpy as np
from sklearn.decomposition import IncrementalPCA
from spicy.sparse import csr_matrix


class Features:
    def __call__(self, pe_filenames, train=True) -> List:
        raise NotImplementedError()
    

# class BatchedPCA(IncrementalPCA):
#     def fit_transform(self, filename):
#         X = np.load('tmp.npy')
#         shape = X.shape
#         dtype = X.dtype
#         del X

#         # Load the data in batches using memmap
#         # todo! dont use offset, just slice dataset
#         n_batches = shape[0] // self.batch_size + 1
#         data = np.memmap(filename, mode="r", dtype=dtype,
#                                 offset=0,
#                                 shape=shape)
#         start = 0
#         for i in range(n_batches):
#             # Apply incremental PCA to the batch
#             self.partial_fit(data[start:start+self.batch_size])
#             start += self.batch_size
            
#             # Save the transformed data to disk
#             # data_batch_transformed = ipca.transform(data_batch)
#             # np.save(f"data_batch_{i}.npy", data_batch_transformed)
        
#         return self.transform(data)


class FeatureExtractor(Features):
    def __init__(self, feature_extractors: List[Features] = None):
        if feature_extractors is None:
            feature_extractors = [
                BasicFeatures(),
                TfIdfFuncs(),
            ]
        self.feature_extractors = feature_extractors

    def __call__(self, pe_filenames, train=True) -> List:
        features = []
        for f in self.feature_extractors:
            features.extend(f(pe_filenames, train))
        return features


# todo do tfidft but only over libraries, imports and sections that you can find in malware
class TfIdfFuncs(Features):
    def __init__(self) -> None:
        self.vectorizers = None

    def __call__(self, pe_filenames: List[str], train=True) -> List:
        if not train and self.vectorizers is None:
            raise Exception("Have to first call train")

        import lief
        from sklearn.feature_extraction.text import TfidfVectorizer

        # List to store the imported function lists for each PE file
        func_matrix = []
        library_matrix = []

        # Iterate through the PE files and get the list of imported functions for each file
        non_parsed = 0
        for f in tqdm(pe_filenames):
            binary = lief.parse(f)

            if binary is None:
                non_parsed += 1
                warnings.warn(f"{non_parsed}: Binary {f} not able to parse")
                continue

            func_list = []
            library_list = []
            for imported_library in binary.imports:
                library_list.append(imported_library.name)
                for func in imported_library.entries:
                    func_list.append(f"{imported_library.name}/{func.name}")

            library_matrix.append(library_list)
            func_matrix.append(func_list)
        
        if train:
            # Create a TF-IDF vectorizer
            vectorizer_imports = TfidfVectorizer(lowercase=False, tokenizer=lambda x: x.split(' '))
            vectorizer_libs = TfidfVectorizer(lowercase=False, tokenizer=lambda x: x.split(' '))
            vectorizer_sect = TfidfVectorizer(lowercase=False, tokenizer=lambda x: x.split(' '))

            # Calculate the TF-IDF scores for the imported functions across all the documents
            tf_idf_imports = vectorizer_imports.fit_transform([" ".join(doc) for doc in func_matrix])
            tf_idf_libs = vectorizer_libs.fit_transform([" ".join(doc) for doc in library_matrix])
            tf_idf_sect = vectorizer_sect.fit_transform([" ".join(doc) for doc in library_matrix])

            self.vectorizers = [
                vectorizer_imports,
                vectorizer_libs,
                vectorizer_sect,
            ]
        else:
            tf_idf_imports = vectorizer_imports.transform([" ".join(doc) for doc in func_matrix])
            tf_idf_libs = vectorizer_libs.transform([" ".join(doc) for doc in library_matrix])
            tf_idf_sect = vectorizer_sect.transform([" ".join(doc) for doc in library_matrix])

        return [tf_idf_imports, tf_idf_libs, tf_idf_sect]


class BasicFeatures(Features):
    def __call__(self, pe_filenames: List[str], train=True):
        import pefile
        # https://github.com/amauricio/sklearn-antimalware/blob/master/test.py

        data_list = []
        non_parsed = 0
        for f in tqdm(pe_filenames):
            try:
                pe = pefile.PE(f)
            except:
                non_parsed += 1
                warnings.warn(f"{non_parsed}: Binary {f} not able to parse")
                continue            

            count_suspicious_functions = 0
            number_packers = 0
            
            name_packers = [
                'UPX',
                'MPRESS',
                'ExeStealth',
                'Morphine',
                'Themida',
            ]
            suspicious_functions_list = [
                'CreateProcess',
                'CreateProcessA',
                'ConnectNamedPipe',
                'CreateFileMapping',
                'CreateRemoteThread',
                'DeviceIoControl',
                'GetAsyncKeyState',
                'GetModuleFilename',
                'GetThreadContext',
                'InternetOpen',
            ]
            entropy = map(lambda x:x.get_entropy(), pe.sections)
            raw_sizes = map(lambda x:x.SizeOfRawData, pe.sections)
            virtual_sizes = map(lambda x:x.Misc_VirtualSize, pe.sections)
            physical_address = map(lambda x:x.Misc_PhysicalAddress, pe.sections)
            virtual_address = map(lambda x:x.VirtualAddress, pe.sections)
            pointer_raw_data = map(lambda x:x.PointerToRawData, pe.sections)
            characteristics = map(lambda x:x.Characteristics, pe.sections)

            data = {
                    'e_magic':pe.DOS_HEADER.e_magic,
                    'e_cblp':pe.DOS_HEADER.e_cblp,
                    'e_cp':pe.DOS_HEADER.e_cp,
                    'e_crlc':pe.DOS_HEADER.e_crlc,
                    'e_cparhdr':pe.DOS_HEADER.e_cparhdr,
                    'e_minalloc':pe.DOS_HEADER.e_minalloc,
                    'e_maxalloc':pe.DOS_HEADER.e_maxalloc,
                    'e_ss':pe.DOS_HEADER.e_ss,
                    'e_sp':pe.DOS_HEADER.e_sp,
                    'e_csum':pe.DOS_HEADER.e_csum,
                    'e_ip':pe.DOS_HEADER.e_ip,
                    'e_cs':pe.DOS_HEADER.e_cs,
                    'e_lfarlc':pe.DOS_HEADER.e_lfarlc,
                    'e_ovno':pe.DOS_HEADER.e_ovno,
                    'e_oemid':pe.DOS_HEADER.e_oemid,
                    'e_oeminfo':pe.DOS_HEADER.e_oeminfo,
                    'e_lfanew':pe.DOS_HEADER.e_lfanew,
                    'Machine':pe.FILE_HEADER.Machine,
                    'NumberOfSections':pe.FILE_HEADER.NumberOfSections,
                    'TimeDateStamp':pe.FILE_HEADER.TimeDateStamp,
                    'PointerToSymbolTable':pe.FILE_HEADER.PointerToSymbolTable,
                    'NumberOfSymbols':pe.FILE_HEADER.NumberOfSymbols,
                    'SizeOfOptionalHeader':pe.FILE_HEADER.SizeOfOptionalHeader,
                    'Characteristics':pe.FILE_HEADER.Characteristics,
                    'Magic':pe.OPTIONAL_HEADER.Magic,
                    'MajorLinkerVersion':pe.OPTIONAL_HEADER.MajorLinkerVersion,
                    'MinorLinkerVersion':pe.OPTIONAL_HEADER.MinorLinkerVersion,
                    'SizeOfCode':pe.OPTIONAL_HEADER.SizeOfCode,
                    'SizeOfInitializedData':pe.OPTIONAL_HEADER.SizeOfInitializedData,
                    'SizeOfUninitializedData':pe.OPTIONAL_HEADER.SizeOfUninitializedData,
                    'AddressOfEntryPoint':pe.OPTIONAL_HEADER.AddressOfEntryPoint,
                    'BaseOfCode':pe.OPTIONAL_HEADER.BaseOfCode,
                    'ImageBase':pe.OPTIONAL_HEADER.ImageBase,
                    'SectionAlignment':pe.OPTIONAL_HEADER.SectionAlignment,
                    'FileAlignment':pe.OPTIONAL_HEADER.FileAlignment,
                    'MajorOperatingSystemVersion':pe.OPTIONAL_HEADER.MajorOperatingSystemVersion,
                    'MinorOperatingSystemVersion':pe.OPTIONAL_HEADER.MinorOperatingSystemVersion,
                    'MajorImageVersion':pe.OPTIONAL_HEADER.MajorImageVersion,
                    'MinorImageVersion':pe.OPTIONAL_HEADER.MinorImageVersion,
                    'MajorSubsystemVersion':pe.OPTIONAL_HEADER.MajorSubsystemVersion,
                    'MinorSubsystemVersion':pe.OPTIONAL_HEADER.MinorSubsystemVersion,
                    'SizeOfHeaders':pe.OPTIONAL_HEADER.SizeOfHeaders,
                    'CheckSum':pe.OPTIONAL_HEADER.CheckSum,
                    'SizeOfImage':pe.OPTIONAL_HEADER.SizeOfImage,
                    'Subsystem':pe.OPTIONAL_HEADER.Subsystem,
                    'DllCharacteristics':pe.OPTIONAL_HEADER.DllCharacteristics,
                    'SizeOfStackReserve':pe.OPTIONAL_HEADER.SizeOfStackReserve,
                    'SizeOfStackCommit':pe.OPTIONAL_HEADER.SizeOfStackCommit,
                    'SizeOfHeapReserve':pe.OPTIONAL_HEADER.SizeOfHeapReserve,
                    'SizeOfHeapCommit':pe.OPTIONAL_HEADER.SizeOfHeapCommit,
                    'LoaderFlags':pe.OPTIONAL_HEADER.LoaderFlags,
                    'NumberOfRvaAndSizes':pe.OPTIONAL_HEADER.NumberOfRvaAndSizes
                }

            try:
                for entry in pe.DIRECTORY_ENTRY_IMPORT:
                    for func in entry.imports:
                        if func.name.decode('utf-8') in suspicious_functions_list:
                            count_suspicious_functions+=1
                data['SuspiciousImportFunctions'] = count_suspicious_functions
            except AttributeError:
                data['SuspiciousImportFunctions'] = 0

            try:
                for entry in pe.sections:
                    try:
                        entry.Name.decode('utf-8')
                    except Exception:
                        number_packers+=1
                    if entry.Name in name_packers:
                        number_packers+=1
                    
                data['SuspiciousNameSection'] = number_packers
            except AttributeError as e:
                data['SuspiciousNameSection'] = 0
            try:
                data['SectionsLength'] = len(pe.sections)
            except (ValueError, TypeError):
                data['SectionsLength'] = 0
            try:
                data['SectionMinEntropy'] = min(entropy)
            except (ValueError, TypeError):
                data['SectionMinEntropy'] = 0
            try:
                data['SectionMaxEntropy'] = max(entropy)
            except (ValueError, TypeError):
                data['SectionMaxEntropy'] = 0
            try:
                data['SectionMinRawsize'] = min(raw_sizes)
            except (ValueError, TypeError):
                data['SectionMinRawsize'] = 0
            try:
                data['SectionMaxRawsize'] = max(raw_sizes)
            except (ValueError, TypeError):
                data['SectionMaxRawsize'] = 0
            try:
                data['SectionMinVirtualsize'] = min(virtual_sizes)
            except (ValueError, TypeError):
                data['SectionMinVirtualsize'] = 0
            try:
                data['SectionMaxVirtualsize'] = max(virtual_sizes)
            except (ValueError, TypeError):
                data['SectionMaxVirtualsize'] = 0
            try:
                data['SectionMaxVirtualsize'] = max(virtual_sizes)
            except (ValueError, TypeError):
                data['SectionMaxVirtualsize'] = 0

            try:
                data['SectionMaxPhysical'] = max(physical_address)
            except (ValueError, TypeError):
                data['SectionMaxPhysical'] = 0
            try:
                data['SectionMinPhysical'] = min(physical_address)
            except (ValueError, TypeError):
                data['SectionMinPhysical'] = 0

            try:
                data['SectionMaxVirtual'] = max(virtual_address)
            except (ValueError, TypeError):
                data['SectionMaxVirtual'] = 0
            try:
                data['SectionMinVirtual'] = min(virtual_address)
            except (ValueError, TypeError):
                data['SectionMinVirtual'] = 0

            try:
                data['SectionMaxPointerData'] = max(pointer_raw_data)
            except (ValueError, TypeError):
                data['SectionMaxPointerData'] = 0

            try:
                data['SectionMinPointerData'] = min(pointer_raw_data)
            except (ValueError, TypeError):
                data['SectionMinPointerData'] = 0

            try:
                data['SectionMaxChar'] = max(characteristics)
            except (ValueError, TypeError):
                data['SectionMaxChar'] = 0

            try:
                data['SectionMinChar'] = min(characteristics)
            except (ValueError, TypeError):
                data['SectionMainChar'] = 0

            try:
                data['DirectoryEntryImport'] = (len(pe.DIRECTORY_ENTRY_IMPORT))
                imports = sum([x.imports for x in pe.DIRECTORY_ENTRY_IMPORT], [])
                data['DirectoryEntryImportSize'] = (len(imports))
            except AttributeError:
                data['DirectoryEntryImport'] = 0
                data['DirectoryEntryImportSize'] =0
            #Exports
            try:
                data['DirectoryEntryExport']  = (len(pe.DIRECTORY_ENTRY_EXPORT.symbols))
            except AttributeError:
                # No export
                data['DirectoryEntryExport']  = 0


            data[ 'ImageDirectoryEntryExport' ] = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_EXPORT']].VirtualAddress
            data[ 'ImageDirectoryEntryImport' ] = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_IMPORT']].VirtualAddress
            data[ 'ImageDirectoryEntryResource' ] = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_RESOURCE']].VirtualAddress
            data[ 'ImageDirectoryEntryException' ] = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_EXCEPTION']].VirtualAddress
            data[ 'ImageDirectoryEntrySecurity' ] = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_SECURITY']].VirtualAddress
        
            data_list.append(data)

        return [csr_matrix(pd.DataFrame(data_list).to_numpy())]
