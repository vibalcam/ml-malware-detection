set workers=12
set saved_folder=./saved_models
rem set seed=1234

rem pauc
rem lr {1e-3, 1e-4, 1e-5},
rem wd 2e-4, 1e-2
rem gammas {0.9, 0.5}
rem lambda, tau {0.1, 1, 10}
python train_torch.py ^
    --arch attention ^
    --learning-rate 5e-6 ^
    --gammas 0.9 0.9 ^
    --lbda 0.5 ^
    --tau 1.0 ^
    --weight-decay 2e-4 ^
    --epochs 10 ^
    --batch-size 32 ^
    --optimizer adamw ^
    --loss_type pauc ^
    --warmup-epochs 1 ^
    --save_dir %saved_folder% ^
    --workers %workers% ^
    --evaluate_every 0.5 ^
    --save_every_epochs 4 ^
    --early_stopping_patience 100 ^
    --save defender/att_ember.pkl ^
    --hidden_dim 512 ^
    --n_layers 8 ^
    --num_heads 8 ^
    --dropout_rate 0.5 ^
    --att_dropout 0.5
    rem --use_features



rem python train_torch.py ^
rem     --arch ff ^
rem     --lr 1e-5 ^
rem     --epochs 400 ^
rem     --batch-size 4000 ^
rem     --optimizer 'adamw' ^
rem     --loss_type pauc ^
rem     --warmup-epochs 40 ^
rem     --save_dir %saved_folder% ^
rem     --workers %workers% ^
rem     --evaluate_every 1 ^
rem     --save_every_epochs 20 ^
rem     --early_stopping_patience 100 ^
rem     --save 'defender/att_ember.pkl' ^
rem     --hidden_dim 1024 1024 1024 1024 ^
rem     --num_heads 12 ^
rem     --dropout_rate 0.1 ^
rem     --att_dropout 0.1
rem     rem --use_features

python test.py -m 'defender/att_ember.pkl'
