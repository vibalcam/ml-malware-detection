#!/bin/bash

workers=12
saved_folder='./saved_models'
# seed=1234

# python train_torch.py \
#     --lr 1e-5 \
#     --epochs 400 \
#     --batch-size 2096 \
#     --optimizer 'adamw' \
#     --loss_type bce \
#     --warmup-epochs 40 \
#     --save_dir $saved_folder \
#     --workers $workers \
#     --evaluate_every 5 \
#     --save_every_epochs 20 \
#     --early_stopping_patience 100 \
#     --save 'defender/att_ember.pkl' \
#     --hidden_dim 512 512 512 512 512 512 512 512 \
#     --num_heads 4 \
#     --dropout_rate 0.3 \
#     --att_dropout 0.1

## pauc
# lr {1e-3, 1e-4, 1e-5}, 5e-6
# wd 2e-4, 1e-2
# gammas {0.9, 0.5}
# lambda, tau {0.1, 1, 10}
python train_torch.py \
    --arch attention \
    --learning-rate 5e-7 \
    --gammas 0.9 0.9 \
    --lbda 0.5 \
    --tau 10.0 \
    --weight-decay 2e-4 \
    --epochs 5 \
    --batch-size 32 \
    --optimizer 'adamw' \
    --loss_type bce \
    --warmup-epochs 0.5 \
    --save_dir $saved_folder \
    --workers $workers \
    --evaluate_every 0.25 \
    --save_every_epochs 1 \
    --early_stopping_patience 100 \
    --save 'defender/att_ember.pkl' \
    --hidden_dim 256 \
    --n_layers 12 \
    --num_heads 8 \
    --dropout_rate 0.7 \
    --att_dropout 0.7
    # --seed 123456
    # --use_features



# python train_torch.py \
#     --arch ff \
#     --lr 1e-5 \
#     --epochs 400 \
#     --batch-size 4000 \
#     --optimizer 'adamw' \
#     --loss_type pauc \
#     --warmup-epochs 40 \
#     --save_dir $saved_folder \
#     --workers $workers \
#     --evaluate_every 1 \
#     --save_every_epochs 20 \
#     --early_stopping_patience 100 \
#     --save 'defender/att_ember.pkl' \
#     --hidden_dim 1024 1024 1024 1024 \
#     --num_heads 12 \
#     --dropout_rate 0.1 \
#     --att_dropout 0.1
#     # --use_features


### full
# python train_torch.py \
#     --lr 1e-5 \
#     --epochs 400 \
#     --batch-size 2048 \
#     --optimizer 'adamw' \
#     --loss_type pauc \
#     --warmup-epochs 40 \
#     --save_dir $saved_folder \
#     --workers $workers \
#     --evaluate_every 5 \
#     --save_every_epochs 20 \
#     --early_stopping_patience 100 \
#     --save 'defender/att_ember.pkl' \
#     --hidden_dim 768 768 768 768 768 768 768 768 \
#     --num_heads 8 \
#     --dropout_rate 0.1 \
#     --att_dropout 0.1
#     # --use_features






# python train_torch.py \
#     --lr 1e-5 \
#     --epochs 600 \
#     --batch-size 2096 \
#     --optimizer 'adamw' \
#     --loss_type pauc \
#     --warmup-epochs 40 \
#     --save_dir $saved_folder \
#     --workers $workers \
#     --evaluate_every 5 \
#     --save_every_epochs 20 \
#     --early_stopping_patience 100 \
#     --save 'defender/att_ember.pkl' \
#     --hidden_dim 512 1024 1024 1024 1024 1024 1024 1024 \
#     --num_heads 4 \
#     --dropout_rate 0.4 \
#     --att_dropout 0.1

python test.py -m 'defender/att.pkl'

# python train_torch.py \
#     --lr 0.001 \
#     --epochs 200 \
#     --batch-size 2096 \
#     --wd 1e-4 \
#     --optimizer 'adamw' \
#     --loss_type auc \
#     --warmup-epochs 20 \
#     --save_dir $saved_folder \
#     --workers $workers \
#     --evaluate_every 10 \
#     --save_every_epochs 20 \
#     --early_stopping_patience 1000 \
#     --save 'defender/att_ember.pkl' \
#     --hidden_dim 256 256 256 256 256 256 \
#     --num_heads 4 \
#     --dropout_rate 0.1 \
#     --att_dropout 0.0
